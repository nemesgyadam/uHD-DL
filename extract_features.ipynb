{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "import h5py\n",
    "\n",
    "mne.set_log_level('error')\n",
    "\n",
    "from utils.load import Load\n",
    "from config.default import cfg\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Load(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this one-by-one to process all subjects in the dataset\n",
    "# Yeah, Im lazy, shut up!\n",
    "subject_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_runs = loader.load_subject(subject_id = subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_runs = raw_runs.copy()\n",
    "\n",
    "drop_bad = False\n",
    "for run in preprocessed_runs:\n",
    "    run = run.resample(200)\n",
    "    if drop_bad:\n",
    "        run = run.drop_channels(cfg['bad_channels'][cfg['subjects'][subject_id]])\n",
    "        run = run.set_eeg_reference('average', projection=False)\n",
    "        not_ROI = [x for x in cfg['not_ROI_channels'] if x not in cfg['bad_channels'][cfg['subjects'][subject_id]]]\n",
    "\n",
    "        run = run.drop_channels(not_ROI)\n",
    "    else:\n",
    "        run = run.set_eeg_reference('average', projection=False)\n",
    "        run = run.drop_channels(cfg['not_ROI_channels'])                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The features extracted are band power features for the\n",
    "mu and beta bands\n",
    "'''\n",
    "mus = []\n",
    "betas = []\n",
    "for i in range(len(preprocessed_runs)):\n",
    "    mus.append(preprocessed_runs[i].copy().filter(l_freq=8, h_freq=12))\n",
    "    betas.append(preprocessed_runs[i].copy().filter(l_freq=13, h_freq=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The EEG data were band-pass filtered for the respective frequency\n",
    "band, and the power was calculated by squaring each time\n",
    "sample. \n",
    "Then the power was estimated in non-overlapping\n",
    "0.25 s segments by averaging the power samples and applying\n",
    "a centered moving average with a 0.75 s window length.\n",
    "band power features were log-transformed\n",
    "power shift compensation was applied, subtracting the mean band power over the last 25 s.\n",
    "the band power features were epoched using 0.5 s pre-and 7 s post-cue.\n",
    "'''\n",
    "\n",
    "\n",
    "        \n",
    "def get_feature(data, freq = 200):\n",
    "    # Calculate power by squaring each time sample\n",
    "    power_eeg_data = np.square(data)\n",
    "\n",
    "    # Define segment parameters\n",
    "    segment_length = int(0.25 * freq)\n",
    "   \n",
    "   \n",
    "    power_eeg_data = power_eeg_data.reshape(power_eeg_data.shape[0], -1, segment_length)\n",
    "    power_eeg_data = np.mean(power_eeg_data, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "    # def centered_moving_average(data, window_size):\n",
    "    #     half_window = window_size // 2\n",
    "    #     cumsum = np.cumsum(data, axis=-1)\n",
    "    #     cumsum[..., window_size:] = cumsum[..., window_size:] - cumsum[..., :-window_size]\n",
    "    #     return (cumsum[..., window_size - 1:-window_size + 1] / window_size)\n",
    "    # power_eeg_data = centered_moving_average(power_eeg_data, 3)\n",
    "\n",
    "\n",
    "    power_eeg_data = np.log(power_eeg_data)\n",
    "    return power_eeg_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thumb\n",
      "(50, 158, 30, 2)\n",
      "index\n",
      "(50, 158, 30, 2)\n",
      "middle\n",
      "(50, 158, 30, 2)\n",
      "ring\n",
      "(50, 158, 30, 2)\n",
      "little\n",
      "(50, 158, 30, 2)\n"
     ]
    }
   ],
   "source": [
    "sfreq = raw_runs[0].info['sfreq']\n",
    "\n",
    "\n",
    "tmin = -0.5\n",
    "tmax = 7\n",
    "\n",
    "\n",
    "\n",
    "def get_baseline(data, length = 25): # 25s\n",
    "    end = data[..., -int(length*sfreq):]\n",
    "    end = get_feature(end, sfreq)\n",
    "    return np.mean(end, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "features = {'thumb': [], 'index': [], 'middle': [], 'ring': [], 'little': []}\n",
    "for i in range(len(preprocessed_runs)):\n",
    "    events, _ = mne.events_from_annotations(preprocessed_runs[i])\n",
    "\n",
    "    mu_baseline = get_baseline(mus[i].get_data())\n",
    "    beta_baseline = get_baseline(betas[i].get_data())\n",
    "\n",
    "    for trigger in events:\n",
    "        if trigger[-1] in [2, 3, 4, 5, 6]: # Drop 'No instruction' and 'Rest' events\n",
    "            # Epoching\n",
    "            mu_data = mus[i].get_data()[...,trigger[0]+int(tmin*sfreq):trigger[0]+int(tmax*sfreq)] \n",
    "            beta_data = betas[i].get_data()[...,trigger[0]+int(tmin*sfreq):trigger[0]+int(tmax*sfreq)] \n",
    "          \n",
    "\n",
    "            # feature extraction\n",
    "            mu_data = get_feature(mu_data, sfreq)\n",
    "            beta_data = get_feature(beta_data, sfreq)\n",
    "\n",
    "            # power shift compensation\n",
    "            mu_data-=mu_baseline[:,np.newaxis]\n",
    "            beta_data-=beta_baseline[:,np.newaxis]\n",
    "\n",
    "\n",
    "            # Format data\n",
    "            data =  np.stack((mu_data, beta_data), axis=-1)\n",
    "            \n",
    "            # Append data to the right list\n",
    "            features[cfg['mapping'][trigger[-1]]].append(data)\n",
    "           \n",
    " \n",
    "for feature in features:\n",
    "    features[feature] = np.array(features[feature])\n",
    "    print(feature)\n",
    "    print(features[feature].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = 'features'\n",
    "tag = '0_25powers'\n",
    "# Save the dictionary to an HDF5 file\n",
    "file_path = os.path.join(target_dir, tag+'_'+cfg['subjects'][subject_id] + '.h5')\n",
    "with h5py.File(file_path, 'w') as h5file:\n",
    "    for key, value in features.items():\n",
    "        h5file.create_dataset(key, data=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cefe38f745df9e33a66570f2e5a410ba71c4ae3bf929b6ad1b474ac5f904d76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

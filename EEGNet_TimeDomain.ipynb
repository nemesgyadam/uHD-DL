{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "import h5py\n",
    "\n",
    "mne.set_log_level('error')\n",
    "\n",
    "from utils.load import Load\n",
    "from config.default import cfg\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from models.eegnet import EEGNet\n",
    "from torchsummary import summary\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Load(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this one-by-one to process all subjects in the dataset\n",
    "# Yeah, Im lazy, shut up!\n",
    "subject_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UHD_Dataset(Dataset):\n",
    "    def __init__(self, subject_id, split, device=\"cpu\", config=\"default\", verbose=False):\n",
    "        self.split = split\n",
    "        self.device = device\n",
    "        raw_runs = loader.load_subject(subject_id = subject_id)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        preprocessed_runs = raw_runs\n",
    "\n",
    "        for run in preprocessed_runs:\n",
    "            run = run.resample(200)\n",
    "            run = run.notch_filter(60)\n",
    "            run = run.filter(8, 25)\n",
    "            run = run.set_eeg_reference('average', projection=False)\n",
    "            run = run.drop_channels(cfg['not_ROI_channels'])  \n",
    "\n",
    "        def create_epochs(raw):\n",
    "                events, event_ids = mne.events_from_annotations(raw)\n",
    "                return mne.Epochs(\n",
    "                    raw,\n",
    "                    events=events,\n",
    "                    event_id=event_ids,\n",
    "                    tmin=-2,\n",
    "                    tmax=7,\n",
    "                    baseline=(-2,0),\n",
    "                    preload=True,\n",
    "                )\n",
    "\n",
    "        epochs = [create_epochs(run) for run in preprocessed_runs]\n",
    "        epochs = mne.concatenate_epochs(epochs)\n",
    "        epochs = epochs.crop(0, 7)\n",
    "\n",
    "        X = epochs.get_data()\n",
    "        orig_shape = X.shape\n",
    "        X = X.reshape(X.shape[0], -1)\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        X = X.reshape(orig_shape)\n",
    "\n",
    "\n",
    "\n",
    "        self.X = X\n",
    "        self.y = epochs.events[:, -1]-2\n",
    "\n",
    "        train_X, test_X, train_y, test_y = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
    "        if self.split == 'train':\n",
    "            self.X = train_X\n",
    "            self.y = train_y\n",
    "        elif self.split == 'test':\n",
    "            self.X = test_X\n",
    "            self.y = test_y\n",
    "\n",
    "        self.X = torch.from_numpy(self.X).float()\n",
    "        self.y = torch.from_numpy(self.y).long()\n",
    "\n",
    "        self.X = self.X.to(self.device)\n",
    "        self.y = self.y.to(self.device)\n",
    "\n",
    "        self.time_steps = self.X.shape[-1]\n",
    "        self.channels = self.X.shape[-2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 0\n",
    "batch_size = 5\n",
    "\n",
    "train_runs = [0,1,2,3]\n",
    "test_runs = [4]\n",
    "\n",
    "train_dataset = UHD_Dataset(subject, 'train', device = device)\n",
    "test_dataset = UHD_Dataset(subject, 'test', device = device)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,  batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 200 samples\n",
      "Test dataset: 50 samples\n",
      "torch.Size([5, 158, 1401])\n",
      "tensor([1, 1, 1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "for features, label in train_dataloader:\n",
    "    print(features.shape)\n",
    "    print(label)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            512\n",
      "├─BatchNorm2d: 1-2                       16\n",
      "├─Conv2d: 1-3                            2,528\n",
      "├─BatchNorm2d: 1-4                       32\n",
      "├─ELU: 1-5                               --\n",
      "├─AvgPool2d: 1-6                         --\n",
      "├─Dropout: 1-7                           --\n",
      "├─Conv2d: 1-8                            256\n",
      "├─Conv2d: 1-9                            128\n",
      "├─BatchNorm2d: 1-10                      16\n",
      "├─AvgPool2d: 1-11                        --\n",
      "├─Dropout: 1-12                          --\n",
      "├─Flatten: 1-13                          --\n",
      "├─Linear: 1-14                           1,725\n",
      "=================================================================\n",
      "Total params: 5,213\n",
      "Trainable params: 5,213\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "channels = train_dataset.channels\n",
    "samples = train_dataset.time_steps\n",
    "model = EEGNet(channels = channels, samples= samples, num_classes = 5)\n",
    "model.to(device)\n",
    "summary(model, input_size=(5, 10, *next(iter(train_dataloader))[0][0].shape));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "model(next(iter(train_dataloader))[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(model, dataloader):\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with no_grad():\n",
    "        for features, labels in dataloader:\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return accuracy_score(all_labels, all_predictions) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Loss: 64.22528767585754, Train accuracy: 23.00%, Test accuracy: 14.00%\n",
      "Epoch 10/100, Loss: 63.42068552970886, Train accuracy: 36.50%, Test accuracy: 10.00%\n",
      "Epoch 15/100, Loss: 61.631113052368164, Train accuracy: 40.50%, Test accuracy: 14.00%\n",
      "Epoch 20/100, Loss: 57.01328504085541, Train accuracy: 53.00%, Test accuracy: 14.00%\n",
      "Epoch 25/100, Loss: 49.401441395282745, Train accuracy: 59.00%, Test accuracy: 18.00%\n",
      "Epoch 30/100, Loss: 42.51008361577988, Train accuracy: 66.50%, Test accuracy: 14.00%\n",
      "Epoch 35/100, Loss: 35.80991643667221, Train accuracy: 74.00%, Test accuracy: 22.00%\n",
      "Epoch 40/100, Loss: 30.603190273046494, Train accuracy: 81.00%, Test accuracy: 18.00%\n",
      "Epoch 45/100, Loss: 25.391809657216072, Train accuracy: 83.50%, Test accuracy: 14.00%\n",
      "Epoch 50/100, Loss: 20.543932557106018, Train accuracy: 87.00%, Test accuracy: 18.00%\n",
      "Epoch 55/100, Loss: 17.0146426782012, Train accuracy: 91.50%, Test accuracy: 18.00%\n",
      "Epoch 60/100, Loss: 14.17531968653202, Train accuracy: 96.00%, Test accuracy: 12.00%\n",
      "Epoch 65/100, Loss: 11.725177437067032, Train accuracy: 94.00%, Test accuracy: 14.00%\n",
      "Epoch 70/100, Loss: 8.791946671903133, Train accuracy: 97.00%, Test accuracy: 16.00%\n",
      "Epoch 75/100, Loss: 7.148144260048866, Train accuracy: 98.50%, Test accuracy: 14.00%\n",
      "Epoch 80/100, Loss: 5.472124982625246, Train accuracy: 99.50%, Test accuracy: 14.00%\n",
      "Epoch 85/100, Loss: 4.288330852985382, Train accuracy: 100.00%, Test accuracy: 14.00%\n",
      "Epoch 90/100, Loss: 3.257483124732971, Train accuracy: 100.00%, Test accuracy: 14.00%\n",
      "Epoch 95/100, Loss: 2.4339390378445387, Train accuracy: 100.00%, Test accuracy: 14.00%\n",
      "Epoch 100/100, Loss: 2.0490054693073034, Train accuracy: 100.00%, Test accuracy: 14.00%\n",
      "##################################################\n",
      "Final_loss: 2.0490054693073034\n",
      "Final train accuracy: 100.00%\n",
      "Final test accuracy: 14.00%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "    \n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        train_accuracy = accuracy(model, train_dataloader)\n",
    "        test_accuracy = accuracy(model, test_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{100}, Loss: {epoch_loss}, Train accuracy: {train_accuracy:.2f}%, Test accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"#\"*50)\n",
    "print(f'Final_loss: {epoch_loss}')\n",
    "print(f'Final train accuracy: {accuracy(model, train_dataloader):.2f}%')\n",
    "print(f'Final test accuracy: {accuracy(model, test_dataloader):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cefe38f745df9e33a66570f2e5a410ba71c4ae3bf929b6ad1b474ac5f904d76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

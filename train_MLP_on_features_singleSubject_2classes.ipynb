{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MLP for each finger pair!\\\n",
    "Using hyper param optimalization\n",
    "Data source: \\\n",
    "sliding windowed powers for mu and beta band\\\n",
    "Subject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "import mne\n",
    "from random import shuffle\n",
    "\n",
    "mne.set_log_level('error')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "from utils.load import Load\n",
    "from config.default import cfg\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index (50, 6732)\n",
      "little (50, 6732)\n",
      "middle (50, 6732)\n",
      "ring (50, 6732)\n",
      "thumb (50, 6732)\n"
     ]
    }
   ],
   "source": [
    "# Load the dictionary from the HDF5 file\n",
    "target_dir = 'features'\n",
    "file_path = os.path.join(target_dir, cfg['subjects'][subject_id] + '.h5')\n",
    "\n",
    "\n",
    "data = {}\n",
    "with h5py.File(file_path, 'r') as h5file:\n",
    "    for key in h5file.keys():\n",
    "        data[key] = np.array(h5file[key])\n",
    "\n",
    "# Print the loaded data dictionary\n",
    "for key, value in data.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, activation):\n",
    "        super(SingleLayerMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = activation\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, y_test, model, criterion, optimizer, num_epochs=100):\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 100, 2000)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128)\n",
    "    activation_name = trial.suggest_categorical(\"activation\", [\"relu\", \"elu\", \"leaky_relu\"])\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"SGD\", \"Adam\"])\n",
    "\n",
    "    if activation_name == \"relu\":\n",
    "        activation = nn.ReLU()\n",
    "    elif activation_name == \"elu\":\n",
    "        activation = nn.ELU()\n",
    "    elif activation_name == \"leaky_relu\":\n",
    "        activation = nn.LeakyReLU()\n",
    "\n",
    "    if optimizer == \"SGD\":\n",
    "        optimizer = optim.SGD\n",
    "    elif optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = SingleLayerMLP(train_X.shape[1], hidden_size, 2, activation)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
    "    return train(train_X, train_y, test_X, test_y, model, criterion, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "    # kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    # fold_accuracies = []\n",
    "\n",
    "    # for train_index, test_index in kf.split(X):\n",
    "    #     X_train, X_test = X[train_index], X[test_index]\n",
    "    #     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #     model = SingleLayerMLP(X_train.shape[1], hidden_size, 2, activation)\n",
    "    #     criterion = nn.CrossEntropyLoss()\n",
    "    #     optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
    "    #     acc = train(X_train, y_train, X_test, y_test, model, criterion, optimizer, num_epochs=num_epochs)\n",
    "    #     fold_accuracies.append(acc)\n",
    "\n",
    "    # mean_accuracy = np.mean(fold_accuracies)\n",
    "    # return mean_accuracy\n",
    "\n",
    "def train_MLP(finger1, finger2, verbose = True):\n",
    "   \n",
    "    print(f'Training MLP for {finger1} vs {finger2}')\n",
    "\n",
    "    X = np.concatenate((data[finger1], data[finger2]), axis=0)\n",
    "    y = np.concatenate((np.ones(data[finger1].shape[0]), np.zeros(data[finger2].shape[0])), axis=0)\n",
    "\n",
    "    X,y = shuffle(X,y)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, X, y), n_trials=10)\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "\n",
    "    print(f'Best trial params: {best_trial.params}')\n",
    "    print(f'Best trial accuracy: {best_trial.value * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP for middle vs ring\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Random.shuffle() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_MLP(\u001b[39m'\u001b[39;49m\u001b[39mmiddle\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mring\u001b[39;49m\u001b[39m'\u001b[39;49m, verbose \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[5], line 70\u001b[0m, in \u001b[0;36mtrain_MLP\u001b[1;34m(finger1, finger2, verbose)\u001b[0m\n\u001b[0;32m     67\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((data[finger1], data[finger2]), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     68\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((np\u001b[39m.\u001b[39mones(data[finger1]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), np\u001b[39m.\u001b[39mzeros(data[finger2]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m X,y \u001b[39m=\u001b[39m shuffle(X,y)\n\u001b[0;32m     71\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m     72\u001b[0m X \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(X)\n",
      "\u001b[1;31mTypeError\u001b[0m: Random.shuffle() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "train_MLP('middle', 'ring', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:42:12,737]\u001b[0m A new study created in memory with name: no-name-5a83cdb7-bcfd-46d5-aeae-191b0479f31b\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP for little vs index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:42:16,799]\u001b[0m Trial 0 finished with value: 0.35 and parameters: {'learning_rate': 0.019038652445492337, 'num_epochs': 1867, 'hidden_size': 24, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 0 with value: 0.35.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:19,418]\u001b[0m Trial 1 finished with value: 0.4 and parameters: {'learning_rate': 0.005486859007369514, 'num_epochs': 1264, 'hidden_size': 53, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.4.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:20,172]\u001b[0m Trial 2 finished with value: 0.5 and parameters: {'learning_rate': 0.0030136666718723693, 'num_epochs': 441, 'hidden_size': 29, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 2 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:27,138]\u001b[0m Trial 3 finished with value: 0.55 and parameters: {'learning_rate': 0.0029383246394954587, 'num_epochs': 960, 'hidden_size': 100, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 3 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:29,922]\u001b[0m Trial 4 finished with value: 0.4 and parameters: {'learning_rate': 0.001509034586537339, 'num_epochs': 1451, 'hidden_size': 65, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:32,211]\u001b[0m Trial 5 finished with value: 0.4 and parameters: {'learning_rate': 3.1127897412545034e-05, 'num_epochs': 1219, 'hidden_size': 31, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 3 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:36,302]\u001b[0m Trial 6 finished with value: 0.45 and parameters: {'learning_rate': 0.0018865814253045854, 'num_epochs': 1184, 'hidden_size': 118, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:41,209]\u001b[0m Trial 7 finished with value: 0.5 and parameters: {'learning_rate': 1.2650828420129235e-05, 'num_epochs': 1767, 'hidden_size': 91, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:41,930]\u001b[0m Trial 8 finished with value: 0.4 and parameters: {'learning_rate': 0.004421044175265824, 'num_epochs': 262, 'hidden_size': 79, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:43,609]\u001b[0m Trial 9 finished with value: 0.4 and parameters: {'learning_rate': 0.010965521360316106, 'num_epochs': 1591, 'hidden_size': 37, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:43,623]\u001b[0m A new study created in memory with name: no-name-4aecfbf0-2d09-4e2b-9022-8b3cb4867602\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 0.0029383246394954587, 'num_epochs': 960, 'hidden_size': 100, 'activation': 'leaky_relu', 'optimizer': 'Adam'}\n",
      "Best trial accuracy: 55.00%\n",
      "Training MLP for middle vs index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:42:49,428]\u001b[0m Trial 0 finished with value: 0.65 and parameters: {'learning_rate': 0.0008488758543516051, 'num_epochs': 1011, 'hidden_size': 90, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 0 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:49,860]\u001b[0m Trial 1 finished with value: 0.6 and parameters: {'learning_rate': 0.0035946072968360394, 'num_epochs': 217, 'hidden_size': 56, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 0 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:54,875]\u001b[0m Trial 2 finished with value: 0.7 and parameters: {'learning_rate': 0.0002462211311570272, 'num_epochs': 1970, 'hidden_size': 93, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:57,177]\u001b[0m Trial 3 finished with value: 0.6 and parameters: {'learning_rate': 0.010647837456255882, 'num_epochs': 888, 'hidden_size': 84, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:42:58,526]\u001b[0m Trial 4 finished with value: 0.55 and parameters: {'learning_rate': 0.035742375290901095, 'num_epochs': 332, 'hidden_size': 120, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:00,691]\u001b[0m Trial 5 finished with value: 0.4 and parameters: {'learning_rate': 8.432575492949026e-05, 'num_epochs': 1010, 'hidden_size': 73, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:07,975]\u001b[0m Trial 6 finished with value: 0.5 and parameters: {'learning_rate': 0.0478653560472796, 'num_epochs': 1360, 'hidden_size': 63, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 2 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:09,207]\u001b[0m Trial 7 finished with value: 0.6 and parameters: {'learning_rate': 2.732508672221359e-05, 'num_epochs': 415, 'hidden_size': 86, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:10,935]\u001b[0m Trial 8 finished with value: 0.55 and parameters: {'learning_rate': 0.004604212598367474, 'num_epochs': 1948, 'hidden_size': 27, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:12,862]\u001b[0m Trial 9 finished with value: 0.45 and parameters: {'learning_rate': 0.00287902301274053, 'num_epochs': 706, 'hidden_size': 102, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:12,873]\u001b[0m A new study created in memory with name: no-name-093b465b-2ccb-4c85-84a2-099c09fd0433\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 0.0002462211311570272, 'num_epochs': 1970, 'hidden_size': 93, 'activation': 'relu', 'optimizer': 'SGD'}\n",
      "Best trial accuracy: 70.00%\n",
      "Training MLP for middle vs little\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:43:14,118]\u001b[0m Trial 0 finished with value: 0.55 and parameters: {'learning_rate': 6.727207316048538e-05, 'num_epochs': 290, 'hidden_size': 61, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 0 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:15,748]\u001b[0m Trial 1 finished with value: 0.6 and parameters: {'learning_rate': 0.015187989173855129, 'num_epochs': 485, 'hidden_size': 117, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.6.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:23,692]\u001b[0m Trial 2 finished with value: 0.45 and parameters: {'learning_rate': 0.0006386628359572021, 'num_epochs': 1243, 'hidden_size': 108, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.6.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:24,449]\u001b[0m Trial 3 finished with value: 0.5 and parameters: {'learning_rate': 0.05794826896947571, 'num_epochs': 834, 'hidden_size': 33, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.6.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:28,260]\u001b[0m Trial 4 finished with value: 0.4 and parameters: {'learning_rate': 0.008495181825580385, 'num_epochs': 1982, 'hidden_size': 63, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.6.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:29,431]\u001b[0m Trial 5 finished with value: 0.45 and parameters: {'learning_rate': 5.8361753887739215e-05, 'num_epochs': 262, 'hidden_size': 68, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.6.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:38,425]\u001b[0m Trial 6 finished with value: 0.55 and parameters: {'learning_rate': 3.1532143304343234e-05, 'num_epochs': 1581, 'hidden_size': 96, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.6.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:43,611]\u001b[0m Trial 7 finished with value: 0.45 and parameters: {'learning_rate': 1.1108035852557955e-05, 'num_epochs': 1885, 'hidden_size': 87, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.6.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:44,137]\u001b[0m Trial 8 finished with value: 0.65 and parameters: {'learning_rate': 2.3343230707898542e-05, 'num_epochs': 776, 'hidden_size': 22, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 8 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:46,108]\u001b[0m Trial 9 finished with value: 0.6 and parameters: {'learning_rate': 0.07828277126843966, 'num_epochs': 665, 'hidden_size': 35, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:46,119]\u001b[0m A new study created in memory with name: no-name-b4f48072-a192-4f9f-aa92-8bf1fe612e70\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 2.3343230707898542e-05, 'num_epochs': 776, 'hidden_size': 22, 'activation': 'relu', 'optimizer': 'SGD'}\n",
      "Best trial accuracy: 65.00%\n",
      "Training MLP for ring vs index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:43:47,089]\u001b[0m Trial 0 finished with value: 0.7 and parameters: {'learning_rate': 3.9647143580524804e-05, 'num_epochs': 380, 'hidden_size': 77, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 0 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:47,942]\u001b[0m Trial 1 finished with value: 0.6 and parameters: {'learning_rate': 0.001639919990125073, 'num_epochs': 216, 'hidden_size': 39, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 0 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:52,849]\u001b[0m Trial 2 finished with value: 0.75 and parameters: {'learning_rate': 0.010364215474150805, 'num_epochs': 354, 'hidden_size': 126, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 2 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:54,772]\u001b[0m Trial 3 finished with value: 0.6 and parameters: {'learning_rate': 1.3012218398915237e-05, 'num_epochs': 1737, 'hidden_size': 37, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:43:57,701]\u001b[0m Trial 4 finished with value: 0.75 and parameters: {'learning_rate': 0.023160746952126113, 'num_epochs': 861, 'hidden_size': 92, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:44:13,349]\u001b[0m Trial 5 finished with value: 0.7 and parameters: {'learning_rate': 0.07486751413093043, 'num_epochs': 1921, 'hidden_size': 57, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 2 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:44:20,519]\u001b[0m Trial 6 finished with value: 0.65 and parameters: {'learning_rate': 0.000418863793165598, 'num_epochs': 1265, 'hidden_size': 75, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 2 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:44:26,874]\u001b[0m Trial 7 finished with value: 0.65 and parameters: {'learning_rate': 0.010106628128961606, 'num_epochs': 1747, 'hidden_size': 104, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:44:35,723]\u001b[0m Trial 8 finished with value: 0.7 and parameters: {'learning_rate': 0.0023560465561380814, 'num_epochs': 1990, 'hidden_size': 64, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 2 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:44:36,509]\u001b[0m Trial 9 finished with value: 0.7 and parameters: {'learning_rate': 0.016915580952857653, 'num_epochs': 350, 'hidden_size': 75, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:44:36,524]\u001b[0m A new study created in memory with name: no-name-c45ee5d7-5a99-4171-83e7-4a59fa6d9062\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 0.010364215474150805, 'num_epochs': 354, 'hidden_size': 126, 'activation': 'elu', 'optimizer': 'Adam'}\n",
      "Best trial accuracy: 75.00%\n",
      "Training MLP for ring vs little\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:44:47,915]\u001b[0m Trial 0 finished with value: 0.75 and parameters: {'learning_rate': 0.000250063614250819, 'num_epochs': 1345, 'hidden_size': 126, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 0 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:44:56,084]\u001b[0m Trial 1 finished with value: 0.8 and parameters: {'learning_rate': 0.008171304593001442, 'num_epochs': 1976, 'hidden_size': 49, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:03,458]\u001b[0m Trial 2 finished with value: 0.75 and parameters: {'learning_rate': 0.00012686210634308703, 'num_epochs': 1608, 'hidden_size': 105, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:06,030]\u001b[0m Trial 3 finished with value: 0.75 and parameters: {'learning_rate': 0.002635403936842258, 'num_epochs': 1641, 'hidden_size': 18, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:09,948]\u001b[0m Trial 4 finished with value: 0.8 and parameters: {'learning_rate': 0.003304523723901571, 'num_epochs': 522, 'hidden_size': 61, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:12,921]\u001b[0m Trial 5 finished with value: 0.8 and parameters: {'learning_rate': 6.569872885822836e-05, 'num_epochs': 154, 'hidden_size': 125, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:30,152]\u001b[0m Trial 6 finished with value: 0.85 and parameters: {'learning_rate': 0.01711206282822913, 'num_epochs': 1846, 'hidden_size': 103, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 6 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:34,809]\u001b[0m Trial 7 finished with value: 0.75 and parameters: {'learning_rate': 0.00021556780648782957, 'num_epochs': 915, 'hidden_size': 70, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 6 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:40,192]\u001b[0m Trial 8 finished with value: 0.9 and parameters: {'learning_rate': 0.0006790290042193423, 'num_epochs': 1200, 'hidden_size': 49, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:41,195]\u001b[0m Trial 9 finished with value: 0.75 and parameters: {'learning_rate': 0.019579217295918175, 'num_epochs': 143, 'hidden_size': 51, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 8 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:41,222]\u001b[0m A new study created in memory with name: no-name-a822b09b-02a3-4ca2-b4c9-c0738ba75f89\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 0.0006790290042193423, 'num_epochs': 1200, 'hidden_size': 49, 'activation': 'leaky_relu', 'optimizer': 'Adam'}\n",
      "Best trial accuracy: 90.00%\n",
      "Training MLP for ring vs middle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:45:41,667]\u001b[0m Trial 0 finished with value: 0.65 and parameters: {'learning_rate': 0.00037925843860348274, 'num_epochs': 189, 'hidden_size': 18, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 0 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:44,356]\u001b[0m Trial 1 finished with value: 0.65 and parameters: {'learning_rate': 0.06580356843200821, 'num_epochs': 967, 'hidden_size': 56, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 0 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:53,213]\u001b[0m Trial 2 finished with value: 0.65 and parameters: {'learning_rate': 0.0003222872846982819, 'num_epochs': 1416, 'hidden_size': 72, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 0 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:54,227]\u001b[0m Trial 3 finished with value: 0.7 and parameters: {'learning_rate': 0.017621874705548348, 'num_epochs': 810, 'hidden_size': 18, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:45:55,485]\u001b[0m Trial 4 finished with value: 0.8 and parameters: {'learning_rate': 0.06683669490616397, 'num_epochs': 458, 'hidden_size': 51, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 4 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:11,852]\u001b[0m Trial 5 finished with value: 0.6 and parameters: {'learning_rate': 0.0028617430301890196, 'num_epochs': 1935, 'hidden_size': 98, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:14,039]\u001b[0m Trial 6 finished with value: 0.75 and parameters: {'learning_rate': 0.0016870805971832882, 'num_epochs': 522, 'hidden_size': 46, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:23,045]\u001b[0m Trial 7 finished with value: 0.75 and parameters: {'learning_rate': 4.071541460709306e-05, 'num_epochs': 1605, 'hidden_size': 84, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:28,709]\u001b[0m Trial 8 finished with value: 0.6 and parameters: {'learning_rate': 0.0015377059691930525, 'num_epochs': 888, 'hidden_size': 99, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:33,893]\u001b[0m Trial 9 finished with value: 0.75 and parameters: {'learning_rate': 0.0002661404190084406, 'num_epochs': 1020, 'hidden_size': 68, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:33,916]\u001b[0m A new study created in memory with name: no-name-9a57d63e-49eb-4adb-9c9a-4293b28893f3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 0.06683669490616397, 'num_epochs': 458, 'hidden_size': 51, 'activation': 'elu', 'optimizer': 'SGD'}\n",
      "Best trial accuracy: 80.00%\n",
      "Training MLP for thumb vs index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:46:35,270]\u001b[0m Trial 0 finished with value: 0.55 and parameters: {'learning_rate': 0.013666107505261336, 'num_epochs': 357, 'hidden_size': 95, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 0 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:37,437]\u001b[0m Trial 1 finished with value: 0.45 and parameters: {'learning_rate': 1.753254774668689e-05, 'num_epochs': 751, 'hidden_size': 56, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 0 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:43,676]\u001b[0m Trial 2 finished with value: 0.7 and parameters: {'learning_rate': 4.736382262424833e-05, 'num_epochs': 1588, 'hidden_size': 100, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:50,122]\u001b[0m Trial 3 finished with value: 0.75 and parameters: {'learning_rate': 4.06744559223805e-05, 'num_epochs': 1482, 'hidden_size': 114, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:51,015]\u001b[0m Trial 4 finished with value: 0.75 and parameters: {'learning_rate': 0.00255583907591944, 'num_epochs': 236, 'hidden_size': 78, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:46:56,023]\u001b[0m Trial 5 finished with value: 0.65 and parameters: {'learning_rate': 0.00031395701638533256, 'num_epochs': 1015, 'hidden_size': 69, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 3 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:05,190]\u001b[0m Trial 6 finished with value: 0.65 and parameters: {'learning_rate': 0.00042460676568493517, 'num_epochs': 1378, 'hidden_size': 107, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 3 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:11,635]\u001b[0m Trial 7 finished with value: 0.6 and parameters: {'learning_rate': 0.005132908866814384, 'num_epochs': 1204, 'hidden_size': 124, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:15,722]\u001b[0m Trial 8 finished with value: 0.6 and parameters: {'learning_rate': 0.00011590780988614963, 'num_epochs': 988, 'hidden_size': 91, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:17,058]\u001b[0m Trial 9 finished with value: 0.5 and parameters: {'learning_rate': 0.002077735364088051, 'num_epochs': 459, 'hidden_size': 68, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 3 with value: 0.75.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:17,076]\u001b[0m A new study created in memory with name: no-name-33b39f42-5f47-4a4f-84f3-9a0bf8e7fd72\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 4.06744559223805e-05, 'num_epochs': 1482, 'hidden_size': 114, 'activation': 'relu', 'optimizer': 'SGD'}\n",
      "Best trial accuracy: 75.00%\n",
      "Training MLP for thumb vs little\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:47:22,031]\u001b[0m Trial 0 finished with value: 0.6 and parameters: {'learning_rate': 0.0012654368062082614, 'num_epochs': 1321, 'hidden_size': 123, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 0 with value: 0.6.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:23,769]\u001b[0m Trial 1 finished with value: 0.55 and parameters: {'learning_rate': 0.0025025502074912304, 'num_epochs': 1313, 'hidden_size': 22, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 0 with value: 0.6.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:25,704]\u001b[0m Trial 2 finished with value: 0.65 and parameters: {'learning_rate': 0.03621514562196356, 'num_epochs': 688, 'hidden_size': 40, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 2 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:26,196]\u001b[0m Trial 3 finished with value: 0.6 and parameters: {'learning_rate': 0.04074767784956009, 'num_epochs': 178, 'hidden_size': 95, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 2 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:27,624]\u001b[0m Trial 4 finished with value: 0.7 and parameters: {'learning_rate': 0.02343595414612765, 'num_epochs': 414, 'hidden_size': 114, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 4 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:29,581]\u001b[0m Trial 5 finished with value: 0.4 and parameters: {'learning_rate': 0.0005500108533310323, 'num_epochs': 499, 'hidden_size': 125, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 4 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:30,060]\u001b[0m Trial 6 finished with value: 0.65 and parameters: {'learning_rate': 0.00141346784478281, 'num_epochs': 469, 'hidden_size': 16, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:32,890]\u001b[0m Trial 7 finished with value: 0.5 and parameters: {'learning_rate': 0.00011638219189466205, 'num_epochs': 1444, 'hidden_size': 60, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 4 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:33,164]\u001b[0m Trial 8 finished with value: 0.65 and parameters: {'learning_rate': 0.0964680057543592, 'num_epochs': 167, 'hidden_size': 44, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 4 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:37,108]\u001b[0m Trial 9 finished with value: 0.6 and parameters: {'learning_rate': 0.051811772563597716, 'num_epochs': 1788, 'hidden_size': 56, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 4 with value: 0.7.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:37,124]\u001b[0m A new study created in memory with name: no-name-142a285a-e2b1-44e5-9bc9-c899aa49af64\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 0.02343595414612765, 'num_epochs': 414, 'hidden_size': 114, 'activation': 'leaky_relu', 'optimizer': 'SGD'}\n",
      "Best trial accuracy: 70.00%\n",
      "Training MLP for thumb vs middle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:47:37,798]\u001b[0m Trial 0 finished with value: 0.45 and parameters: {'learning_rate': 3.1395805544958564e-05, 'num_epochs': 619, 'hidden_size': 18, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 0 with value: 0.45.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:45,253]\u001b[0m Trial 1 finished with value: 0.65 and parameters: {'learning_rate': 7.017864767254146e-05, 'num_epochs': 1984, 'hidden_size': 93, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:48,656]\u001b[0m Trial 2 finished with value: 0.55 and parameters: {'learning_rate': 0.00017904659762582812, 'num_epochs': 677, 'hidden_size': 67, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:55,909]\u001b[0m Trial 3 finished with value: 0.6 and parameters: {'learning_rate': 0.0044678450820598405, 'num_epochs': 1025, 'hidden_size': 119, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:47:58,335]\u001b[0m Trial 4 finished with value: 0.65 and parameters: {'learning_rate': 0.002468596988624277, 'num_epochs': 1269, 'hidden_size': 57, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:00,511]\u001b[0m Trial 5 finished with value: 0.5 and parameters: {'learning_rate': 0.023088424989038916, 'num_epochs': 719, 'hidden_size': 106, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:02,377]\u001b[0m Trial 6 finished with value: 0.45 and parameters: {'learning_rate': 0.001221777038145882, 'num_epochs': 597, 'hidden_size': 95, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:04,803]\u001b[0m Trial 7 finished with value: 0.65 and parameters: {'learning_rate': 0.010543610403696647, 'num_epochs': 1207, 'hidden_size': 46, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:09,237]\u001b[0m Trial 8 finished with value: 0.6 and parameters: {'learning_rate': 7.094893690711188e-05, 'num_epochs': 1034, 'hidden_size': 40, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:10,929]\u001b[0m Trial 9 finished with value: 0.55 and parameters: {'learning_rate': 0.005018111260202397, 'num_epochs': 681, 'hidden_size': 42, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:10,947]\u001b[0m A new study created in memory with name: no-name-d3b67a14-f53a-4176-9270-9f62d606bf9f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 7.017864767254146e-05, 'num_epochs': 1984, 'hidden_size': 93, 'activation': 'relu', 'optimizer': 'SGD'}\n",
      "Best trial accuracy: 65.00%\n",
      "Training MLP for thumb vs ring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-14 14:48:18,114]\u001b[0m Trial 0 finished with value: 0.8 and parameters: {'learning_rate': 6.319206534323966e-05, 'num_epochs': 1751, 'hidden_size': 49, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 0 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:23,945]\u001b[0m Trial 1 finished with value: 0.9 and parameters: {'learning_rate': 0.048412582012581404, 'num_epochs': 1085, 'hidden_size': 59, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:28,146]\u001b[0m Trial 2 finished with value: 0.9 and parameters: {'learning_rate': 0.00039279527022275214, 'num_epochs': 1458, 'hidden_size': 105, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:29,254]\u001b[0m Trial 3 finished with value: 0.85 and parameters: {'learning_rate': 0.017905221714138483, 'num_epochs': 166, 'hidden_size': 96, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:32,015]\u001b[0m Trial 4 finished with value: 0.85 and parameters: {'learning_rate': 4.8169567737968724e-05, 'num_epochs': 969, 'hidden_size': 101, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:34,764]\u001b[0m Trial 5 finished with value: 0.9 and parameters: {'learning_rate': 0.07575324070258521, 'num_epochs': 633, 'hidden_size': 123, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:45,506]\u001b[0m Trial 6 finished with value: 0.75 and parameters: {'learning_rate': 0.01545100785271337, 'num_epochs': 603, 'hidden_size': 105, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:53,158]\u001b[0m Trial 7 finished with value: 0.75 and parameters: {'learning_rate': 0.00020075572799738232, 'num_epochs': 1048, 'hidden_size': 53, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 1 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:56,399]\u001b[0m Trial 8 finished with value: 0.95 and parameters: {'learning_rate': 6.279837210346075e-05, 'num_epochs': 1510, 'hidden_size': 21, 'activation': 'elu', 'optimizer': 'SGD'}. Best is trial 8 with value: 0.95.\u001b[0m\n",
      "\u001b[32m[I 2023-04-14 14:48:58,190]\u001b[0m Trial 9 finished with value: 0.85 and parameters: {'learning_rate': 0.07152705221044801, 'num_epochs': 423, 'hidden_size': 64, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 8 with value: 0.95.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'learning_rate': 6.279837210346075e-05, 'num_epochs': 1510, 'hidden_size': 21, 'activation': 'elu', 'optimizer': 'SGD'}\n",
      "Best trial accuracy: 95.00%\n"
     ]
    }
   ],
   "source": [
    "for finger1 in data:\n",
    "    for finger2 in data:\n",
    "        if finger1 != finger2:\n",
    "            train_MLP(finger1, finger2)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cefe38f745df9e33a66570f2e5a410ba71c4ae3bf929b6ad1b474ac5f904d76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

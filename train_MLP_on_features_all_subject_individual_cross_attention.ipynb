{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "import mne\n",
    "import math \n",
    "mne.set_log_level('error')\n",
    "\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "from utils.load import Load\n",
    "from config.default import cfg\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1\n",
      "dict_keys(['index', 'little', 'middle', 'ring', 'thumb'])\n",
      "S2\n",
      "dict_keys(['index', 'little', 'middle', 'ring', 'thumb'])\n",
      "S3\n",
      "dict_keys(['index', 'little', 'middle', 'ring', 'thumb'])\n",
      "S4\n",
      "dict_keys(['index', 'little', 'middle', 'ring', 'thumb'])\n",
      "S5\n",
      "dict_keys(['index', 'little', 'middle', 'ring', 'thumb'])\n"
     ]
    }
   ],
   "source": [
    "subject_data = {}\n",
    "# Load the data  from the HDF5 file\n",
    "target_dir = 'features'\n",
    "tag = 'reproduced_with_bad'\n",
    "\n",
    "for subject in cfg['subjects']:\n",
    "    file_path = os.path.join(target_dir, tag+'_'+subject + '.h5')\n",
    "\n",
    "    data = {}\n",
    "    with h5py.File(file_path, 'r') as h5file:\n",
    "        for key in h5file.keys():\n",
    "            data[key] = np.array(h5file[key])\n",
    "\n",
    "    subject_data[subject] = data\n",
    "\n",
    "\n",
    "for subject_id in subject_data:\n",
    "    print(subject_id)\n",
    "    print(subject_data[subject_id].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 250 samples per subject\n",
    "# 1250 total samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.8\n",
    "\n",
    "np.random.seed(42)\n",
    "global_train_features = []\n",
    "global_train_labels = []\n",
    "global_test_features = []\n",
    "global_test_labels = []\n",
    "for s, subject_id in enumerate(subject_data):\n",
    "    data = subject_data[subject_id]\n",
    "\n",
    "    for i, finger in enumerate(data):\n",
    "        \n",
    "        finger_data = data[finger]\n",
    "        \n",
    "        \n",
    "        # RESHAPE\n",
    "        finger_data = finger_data.reshape(finger_data.shape[0], -1)\n",
    "\n",
    "        # Normalize\n",
    "        #finger_data = StandardScaler().fit_transform(finger_data)\n",
    "\n",
    "       \n",
    "        np.random.shuffle(finger_data)\n",
    "\n",
    "        # TO GPU\n",
    "        finger_data = torch.tensor(finger_data).to(torch.float32).to(device)\n",
    "        \n",
    "        ids = torch.tensor(np.ones((len(finger_data))) * s).to(torch.int64).to(device)\n",
    "        features = []\n",
    "        for d in range(len(finger_data)):\n",
    "            features.append((finger_data[d], ids[d]))\n",
    "\n",
    "        labels = torch.tensor(np.ones((len(finger_data))) * i).to(device)\n",
    "\n",
    "        train_features = features[:int(len(finger_data)*train_percent)]\n",
    "        train_labels = labels[:int(len(finger_data)*train_percent)]\n",
    "        test_features = features[int(len(finger_data)*train_percent):]\n",
    "        test_labels = labels[int(len(finger_data)*train_percent):]\n",
    "\n",
    "        global_train_features.extend(train_features)\n",
    "        global_train_labels.extend(train_labels)\n",
    "        global_test_features.extend(test_features)\n",
    "        global_test_labels.extend(test_labels)\n",
    "        \n",
    "      \n",
    "\n",
    "shuffler = np.random.permutation(len(global_train_features))\n",
    "global_train_features = [global_train_features[i] for i in shuffler]\n",
    "global_train_labels = [global_train_labels[i] for i in shuffler]\n",
    "\n",
    "shuffler = np.random.permutation(len(global_test_features))\n",
    "global_test_features = [global_test_features[i] for i in shuffler]\n",
    "global_test_labels = [global_test_labels[i] for i in shuffler]\n",
    "\n",
    "train_X = global_train_features\n",
    "train_y = global_train_labels\n",
    "test_X = global_test_features\n",
    "test_y = global_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = ([EEG], [subject_id])\n",
    "# label = finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feautres shape: torch.Size([8216])\n",
      "Subject_id: 1\n",
      "Label: 3.0\n",
      "------------------\n",
      "Feautres shape: torch.Size([8216])\n",
      "Subject_id: 3\n",
      "Label: 3.0\n",
      "------------------\n",
      "Feautres shape: torch.Size([8216])\n",
      "Subject_id: 2\n",
      "Label: 3.0\n",
      "------------------\n",
      "Feautres shape: torch.Size([8216])\n",
      "Subject_id: 3\n",
      "Label: 3.0\n",
      "------------------\n",
      "Feautres shape: torch.Size([8216])\n",
      "Subject_id: 3\n",
      "Label: 2.0\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# First 5 samples\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Feautres shape: {train_X[i][0].shape}')\n",
    "    print(f'Subject_id: {train_X[i][1]}')\n",
    "    print(f'Label: {train_y[i]}')\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.X[idx][0]\n",
    "        subject_id = self.X[idx][1]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        return (features, subject_id), label\n",
    "\n",
    "train_dataset = CustomDataset(train_X, train_y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(test_X, test_y)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, feature_dim, user_dim, hidden_dim, feautre_hidden_dim,  num_classes):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.user_dim = user_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.feature_hidden_dim = feautre_hidden_dim\n",
    "        self.num_queries = 3\n",
    "\n",
    "        self.layers = nn.ModuleDict({\n",
    "            'feature extractor' : nn.Linear(self.feature_dim,  self.feature_hidden_dim),\n",
    "            'batch norm': nn.BatchNorm1d(self.feature_hidden_dim),\n",
    "            'query layer' : nn.Linear( self.feature_hidden_dim, self.feature_hidden_dim * self.hidden_dim ),  # Query transformation\n",
    "            'key layer' : nn.Linear(self.user_dim, self.hidden_dim *self.user_dim ),  # Key transformation\n",
    "            'value layer': nn.Linear(self.user_dim, self.hidden_dim *self.user_dim ),  # Value transformation\n",
    "            'dropout': nn.Dropout(0.2),\n",
    "            'classifier' : nn.Linear(self.feature_hidden_dim * self.hidden_dim, num_classes)\n",
    "        })\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, features, user_indices):\n",
    "        # Transform features to hidden_dim\n",
    "        features = self.layers['feature extractor'](features)  \n",
    "        features = self.layers['batch norm'](features)\n",
    "       \n",
    "        # Convert user_indices to one_hot vectors\n",
    "        user_one_hot = torch.zeros(user_indices.size(0), self.user_dim, device=user_indices.device)\n",
    "        user_one_hot.scatter_(1, user_indices.unsqueeze(1), 1)\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "        # Transform user_one_hot to query\n",
    "        query = self.layers['query layer'](features)  \n",
    "        query = query.view(-1, self.feature_hidden_dim, self.hidden_dim )  \n",
    "\n",
    "\n",
    "        # Transform features to keys and values\n",
    "        keys = self.layers['key layer'](user_one_hot)  \n",
    "        keys = keys.view(-1,  self.hidden_dim, self.user_dim)  \n",
    "        values = self.layers['value layer'](user_one_hot) \n",
    "        values = values.view(-1,  self.user_dim, self.hidden_dim) \n",
    "        # print(f'query: {query.shape}')\n",
    "        # print(f'keys: {keys.shape}')\n",
    "        # print(f'values: {values.shape}')\n",
    "\n",
    "       \n",
    "        # Calculate attention scores\n",
    "        attention_scores = torch.bmm(query, keys) \n",
    "\n",
    "        # Normalize the attention scores\n",
    "        attention_scores = attention_scores / math.sqrt(self.hidden_dim)\n",
    "\n",
    "        attention_probs = self.softmax(attention_scores) \n",
    "     \n",
    "        # Calculate the attended features\n",
    "        attended_features = torch.bmm(attention_probs, values) \n",
    "        attended_features = attended_features.view(-1, self.feature_hidden_dim * self.hidden_dim)\n",
    "        \n",
    "        # Dropout\n",
    "        attended_features = self.layers['dropout'](attended_features)\n",
    "        \n",
    "        # Classify the attended features\n",
    "        output = self.layers['classifier'](attended_features)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 8216\n",
    "hidden_dim = 2\n",
    "feautre_hidden_dim = 8\n",
    "\n",
    "num_subjects = 5\n",
    "output_size = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─ModuleDict: 1-1                        --\n",
      "|    └─Linear: 2-1                       65,736\n",
      "|    └─BatchNorm1d: 2-2                  16\n",
      "|    └─Linear: 2-3                       144\n",
      "|    └─Linear: 2-4                       60\n",
      "|    └─Linear: 2-5                       60\n",
      "|    └─Dropout: 2-6                      --\n",
      "|    └─Linear: 2-7                       85\n",
      "├─Softmax: 1-2                           --\n",
      "=================================================================\n",
      "Total params: 66,101\n",
      "Trainable params: 66,101\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create model and pass data\n",
    "model = CrossAttention(input_size, num_subjects, hidden_dim, feautre_hidden_dim, output_size)\n",
    "model.to(device)\n",
    "summary(model, input_size=(5, 10, input_size));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "tensor([[-0.5374, -0.3970, -0.0480,  0.1009, -0.1018]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = model(train_X[0][0].unsqueeze(0), train_X[0][1].unsqueeze(0))\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataloader):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features,  labels in dataloader:\n",
    "\n",
    "            outputs = model(features = features[0], user_indices = features[1])\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return accuracy * 100\n",
    "    #print(f\"Accuracy: {accuracy * 100:.2f}% ({correct_predictions}/{total_predictions})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 102.6247946023941, Train accuracy: 23.60%, Test accuracy: 22.40%\n",
      "Epoch 11/100, Loss: 31.48391565680504, Train accuracy: 86.00%, Test accuracy: 18.00%\n",
      "Epoch 21/100, Loss: 11.367946427315474, Train accuracy: 96.80%, Test accuracy: 18.40%\n",
      "Epoch 31/100, Loss: 5.2778927269391716, Train accuracy: 97.80%, Test accuracy: 16.80%\n",
      "Epoch 41/100, Loss: 9.077177939703688, Train accuracy: 91.60%, Test accuracy: 23.60%\n",
      "Epoch 51/100, Loss: 1.878758427221328, Train accuracy: 99.70%, Test accuracy: 20.00%\n",
      "Epoch 61/100, Loss: 6.611761980224401, Train accuracy: 99.00%, Test accuracy: 19.20%\n",
      "Epoch 71/100, Loss: 0.45220420393161476, Train accuracy: 99.90%, Test accuracy: 19.60%\n",
      "Epoch 81/100, Loss: 0.25665980941266753, Train accuracy: 100.00%, Test accuracy: 20.00%\n",
      "Epoch 91/100, Loss: 0.16855421553191263, Train accuracy: 100.00%, Test accuracy: 19.60%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features = batch_features[0], user_indices = batch_features[1])\n",
    "        loss = criterion(outputs, batch_labels.long())\n",
    "          \n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "   \n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        train_accuracy = accuracy(train_dataloader)\n",
    "        test_accuracy = accuracy(test_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss}, Train accuracy: {train_accuracy:.2f}%, Test accuracy: {test_accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cefe38f745df9e33a66570f2e5a410ba71c4ae3bf929b6ad1b474ac5f904d76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

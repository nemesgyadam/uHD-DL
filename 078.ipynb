{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import mne\n",
    "from scipy.signal import butter, filtfilt\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "mne.set_log_level('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'C:/Data/UHD_EEG/'\n",
    "subjects = ['S1', 'S2', 'S3', 'S4', 'S5']\n",
    "dominant_hand = ['left','right','right','right','right']\n",
    "\n",
    "mapping = {0: \"No instruction\", 1: \"Rest\", 2: \"thumb\", 3: \"index\", 4: \"middle\", 5: \"ring\", 6: \"little\"}\n",
    "\n",
    "not_ROI_channels = ['c255', 'c256', 'c254', 'c251', 'c239', 'c240', 'c238', 'c235', 'c224', 'c222', 'c223', 'c219', 'c220', 'c221', 'c215', 'c216', 'c217', 'c213', 'c212', 'c211', 'c210', 'c209', 'c112', 'c110', 'c107', 'c108', 'c103', 'c104', 'c105', 'c101', 'c100', 'c99', 'c98', 'c97', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c14', 'c15', 'c16', 'c23', 'c29', 'c26', 'c17', 'c18', 'c20', 'c19', 'c21', 'c24', 'c22', 'c25', 'c28', 'c33', 'c35', 'c38', 'c42', 'c81', 'c34', 'c37', 'c41', 'c45', 'c36', 'c40', 'c44', 'c39', 'c43', 'c145', 'c147', 'c150', 'c154', 'c157', 'c153', 'c149', 'c146', 'c93', 'c159', 'c156', 'c152', 'c148', 'c95', 'c160', 'c158', 'c155', 'c151', 'c96', 'c202', 'c198', 'c195', 'c193']\n",
    "\n",
    "S01_bad_channels = ['c69', 'c122', 'c170', 'c173', 'c189']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_montage(hemishpere):\n",
    "    mat = scipy.io.loadmat(os.path.join(data_root, 'montage', f'montage_256_{hemishpere}_hemisphere.mat'))\n",
    "    return mat['pos_256']\n",
    "\n",
    "left_handed_montage = get_montage('right')\n",
    "right_handed_montage = get_montage('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_run(subject_id, run, describe=True):\n",
    "    subject = subjects[subject_id]\n",
    "    mat = scipy.io.loadmat(os.path.join(data_root, 'rawdata', subject, run))\n",
    "    data = mat['y'][1:]  # remove timestamp\n",
    "    ch_names = [f'c{i}' for i in range(1, 257)] + ['STIM']\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=mat['SR\\x00'][0][0])\n",
    "\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "    ch_types = {ch: 'eeg' if ch != 'STIM' else 'stim' for ch in ch_names}\n",
    "    raw.set_channel_types(ch_types)\n",
    "\n",
    "    events = mne.find_events(raw, stim_channel='STIM')\n",
    "    annot_from_events = mne.annotations_from_events(events, event_desc=mapping, sfreq=raw.info['sfreq'])\n",
    "    raw.set_annotations(annot_from_events)\n",
    "    raw.drop_channels(['STIM'])\n",
    "\n",
    "    montage_positions = left_handed_montage if dominant_hand[subject_id] == 'left' else right_handed_montage\n",
    "    montage = mne.channels.make_dig_montage(ch_pos=dict(zip(ch_names, montage_positions)), coord_frame='head')\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    if describe:\n",
    "        raw.describe()\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject(subject_id, describe = True):\n",
    "    runs = []\n",
    "    run_files = os.listdir(os.path.join(data_root, 'rawdata', subjects[subject_id]))\n",
    "    for file in run_files:\n",
    "        runs.append(load_run(subject_id, file, describe))\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_runs = load_subject(subject_id = 0, describe = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_runs = raw_runs.copy()\n",
    "for run in preprocessed_runs:\n",
    "    run = run.resample(200)\n",
    "\n",
    "\n",
    "    run = run.drop_channels(S01_bad_channels)\n",
    "    run = run.set_eeg_reference('average', projection=False)\n",
    "    run = run.drop_channels(not_ROI_channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = []\n",
    "betas = []\n",
    "for i in range(len(preprocessed_runs)):\n",
    "    mus.append(preprocessed_runs[i].copy().filter(l_freq=8, h_freq=12))\n",
    "    betas.append(preprocessed_runs[i].copy().filter(l_freq=13, h_freq=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centered_moving_average(data, window_size):\n",
    "        half_window = window_size // 2\n",
    "        cumsum = np.cumsum(data, axis=-1)\n",
    "        cumsum[..., window_size:] = cumsum[..., window_size:] - cumsum[..., :-window_size]\n",
    "        return (cumsum[..., window_size - 1:-window_size + 1] / window_size)\n",
    "\n",
    "\n",
    "        \n",
    "def my_feature(data, freq = 200, flatten = True):\n",
    "    # Calculate power by squaring each time sample\n",
    "    power_eeg_data = np.square(data)\n",
    "\n",
    "    # Remove zero values to avoid log(0)\n",
    "    epsilon = 1e-10\n",
    "    power_eeg_data[power_eeg_data == 0] = epsilon\n",
    "\n",
    "    # Define segment parameters\n",
    "    segment_length = int(0.25 * freq)  # 0.25 s segment length \n",
    "   \n",
    "   \n",
    "    power_eeg_data = power_eeg_data.reshape(power_eeg_data.shape[0], -1, segment_length)\n",
    "    power_eeg_data = np.mean(power_eeg_data, axis=-1)\n",
    "#     print(power_eeg_data.mean(axis=1))\n",
    "    power_eeg_data = centered_moving_average(power_eeg_data, 3)\n",
    "#     print(power_eeg_data.mean(axis=1))\n",
    "\n",
    "\n",
    "    power_eeg_data = np.clip(power_eeg_data, a_min=epsilon, a_max=None)\n",
    "    power_eeg_data = np.log(power_eeg_data)\n",
    "    if flatten:\n",
    "        power_eeg_data = power_eeg_data.flatten()\n",
    "    return power_eeg_data\n",
    "    \n",
    "    std = np.std(power_eeg_data, axis=1)\n",
    "    mean = np.mean(power_eeg_data, axis=1)\n",
    "    # print(\"std.shape: \", std.shape)\n",
    "    # print(\"mean.shape: \", mean.shape)\n",
    "    return np.concatenate((std, mean), axis=0) #  - 5 percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n",
      "(153, 26)\n",
      "(153,)\n"
     ]
    }
   ],
   "source": [
    "middles = [] # 4\n",
    "rings = []   # 5 \n",
    "\n",
    "\n",
    "for i in range(len(preprocessed_runs)):\n",
    "    events, event_ids = mne.events_from_annotations(preprocessed_runs[i])\n",
    "    # last 25 seconds of mu\n",
    "    muend = mus[i].get_data()[..., -int(25*200):]\n",
    "    # last 25 seconds of beta\n",
    "    betaend = betas[i].get_data()[..., -int(25*200):]\n",
    "\n",
    "    muend = my_feature(muend, flatten=False)\n",
    "    betaend = my_feature(betaend, flatten=False)\n",
    "    mu_baseline = np.mean(muend, axis=-1)\n",
    "    beta_baseline = np.mean(betaend, axis=-1)\n",
    "    \n",
    "\n",
    "    for trigger in events:\n",
    "        if trigger[-1] in [4,5]:\n",
    "            #print(trigger)\n",
    "            mu_data = mus[i].get_data()[...,trigger[0]-100:trigger[0]+1400] # 0.5s after trigger to 1.5s after trigger\n",
    "            mu_data -= mu_baseline[:,np.newaxis]\n",
    "            \n",
    "            beta_data = betas[i].get_data()[...,trigger[0]-100:trigger[0]+1400]\n",
    "            beta_data -= beta_baseline[:,np.newaxis]\n",
    "\n",
    "\n",
    "            mu_data = my_feature(mu_data, flatten=False)\n",
    "            beta_data = my_feature(beta_data, flatten=False)\n",
    "\n",
    "            mu_data-=mu_baseline[:,np.newaxis]\n",
    "            beta_data-=beta_baseline[:,np.newaxis]\n",
    "\n",
    "            mu_data = mu_data.flatten()\n",
    "            beta_data = beta_data.flatten()\n",
    "\n",
    "            data = np.concatenate((mu_data, beta_data), axis=0)\n",
    "            \n",
    "            if trigger[-1] == 4:\n",
    "                middles.append(data)\n",
    "            else:\n",
    "                rings.append(data)\n",
    "        \n",
    "\n",
    "            \n",
    "middles = np.array(middles)\n",
    "rings = np.array(rings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7956)\n",
      "(50, 7956)\n",
      "3.7219979134196155\n",
      "-1.4866793741190314\n",
      "0.06047677890877989\n",
      "2.202524927473344\n",
      "-1.421999953482315\n",
      "0.1293654747667082\n"
     ]
    }
   ],
   "source": [
    "print(middles.shape)\n",
    "print(rings.shape)\n",
    "for ring in rings:\n",
    "    print(ring.max())\n",
    "    print(ring.min())\n",
    "    print(ring.mean())\n",
    "    break\n",
    "\n",
    "for middle in middles:\n",
    "    print(middle.max())\n",
    "    print(middle.min())\n",
    "    print(middle.mean())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 7956)\n",
      "(10, 7956)\n",
      "(90,)\n",
      "(10,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle_vs_ring = np.concatenate((middles, rings), axis=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(middle_vs_ring)\n",
    "middle_vs_ring = scaler.transform(middle_vs_ring)\n",
    "\n",
    "\n",
    "y_middle_vs_ring = np.concatenate((np.zeros(middles.shape[0]), np.ones(rings.shape[0])), axis=0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(middle_vs_ring, y_middle_vs_ring, test_size=0.1, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.78\n"
     ]
    }
   ],
   "source": [
    "X = middle_vs_ring\n",
    "y = y_middle_vs_ring\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf','linear'], 'gamma': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "                        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}]\n",
    "grid = GridSearchCV(SVC(), tuned_parameters, cv=StratifiedKFold(n_splits=10), scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cefe38f745df9e33a66570f2e5a410ba71c4ae3bf929b6ad1b474ac5f904d76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
